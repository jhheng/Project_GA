{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      "by             10000 non-null object\n",
      "score          10000 non-null int64\n",
      "time           10000 non-null int64\n",
      "title          9502 non-null object\n",
      "type           10000 non-null object\n",
      "url            4598 non-null object\n",
      "text           10000 non-null object\n",
      "parent         498 non-null float64\n",
      "deleted        0 non-null float64\n",
      "dead           3629 non-null object\n",
      "descendants    8989 non-null float64\n",
      "id             10000 non-null int64\n",
      "ranking        0 non-null float64\n",
      "dtypes: float64(4), int64(3), object(6)\n",
      "memory usage: 1015.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# %load hn.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#this result is from google big query\n",
    "#https://github.com/HackerNews/API for fields definition\n",
    "df = pd.read_csv('/Users/jing/Desktop/GA/Project_GA/hn.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "story      9334\n",
      "pollopt     498\n",
      "job         102\n",
      "poll         66\n",
      "Name: type, dtype: int64\n",
      "              by  score        time title     type  url  \\\n",
      "150      davidst      0  1295598615   NaN  pollopt  NaN   \n",
      "151         pyre      0  1370639741   NaN  pollopt  NaN   \n",
      "152     weixiyen      0  1277926148   NaN  pollopt  NaN   \n",
      "153  ColinWright     28  1365328173   NaN  pollopt  NaN   \n",
      "154         jaxn      0  1296060464   NaN  pollopt  NaN   \n",
      "\n",
      "                                                  text     parent  deleted  \\\n",
      "150                                               8 GB  2126850.0      NaN   \n",
      "151  This has happened to me outside of The Valley/...  5841950.0      NaN   \n",
      "152                                              Bulls  1475884.0      NaN   \n",
      "153  I found that submitted item really interesting...  5506656.0      NaN   \n",
      "154                                             $5mm +  2143802.0      NaN   \n",
      "\n",
      "    dead  descendants       id  ranking  \n",
      "150  NaN          NaN  2126854      NaN  \n",
      "151  NaN          NaN  5841958      NaN  \n",
      "152  NaN          NaN  1475886      NaN  \n",
      "153  NaN          NaN  5506661      NaN  \n",
      "154  NaN          NaN  2143837      NaN  \n"
     ]
    }
   ],
   "source": [
    "print df.type.value_counts()\n",
    "print df[df.parent.notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             by  score  \\\n",
      "time                                     \n",
      "2011-06-22 20:29:14  sagar_shah      1   \n",
      "2012-06-26 20:02:09  pospischil      1   \n",
      "2013-05-19 00:56:11      gpoort      1   \n",
      "2014-03-04 16:26:05      ooshma      1   \n",
      "2014-07-03 04:37:27   greattypo      1   \n",
      "\n",
      "                                                                 title type  \\\n",
      "time                                                                          \n",
      "2011-06-22 20:29:14                           Be Employee or Intern #1  job   \n",
      "2012-06-26 20:02:09                         Come build Custora with us  job   \n",
      "2013-05-19 00:56:11                        Help Scale Rescale (YC W12)  job   \n",
      "2014-03-04 16:26:05  Gobble (YC W14) seeks FTE for Customer Service...  job   \n",
      "2014-07-03 04:37:27  Clever (YC S12) is hiring full-stack engineers...  job   \n",
      "\n",
      "                     url                                               text  \\\n",
      "time                                                                          \n",
      "2011-06-22 20:29:14  NaN  Weâ€™re a yet to be announced YC startup with a ...   \n",
      "2012-06-26 20:02:09  NaN  Hi HN,<p>Custora is a customer analytics tool ...   \n",
      "2013-05-19 00:56:11  NaN  We are a team of six building a simulation pla...   \n",
      "2014-03-04 16:26:05  NaN  Gobble is the first personalized dinner servic...   \n",
      "2014-07-03 04:37:27  NaN  Steve Jobs described education as one of the f...   \n",
      "\n",
      "                     dead  descendants       id  type_numeric  text_length  \\\n",
      "time                                                                         \n",
      "2011-06-22 20:29:14     0          0.0  2685093           0.0         1292   \n",
      "2012-06-26 20:02:09     0          0.0  4163838           0.0         2571   \n",
      "2013-05-19 00:56:11     0          0.0  5731230           0.0         1735   \n",
      "2014-03-04 16:26:05     0          0.0  7341200           0.0         2509   \n",
      "2014-07-03 04:37:27     0          0.0  7981458           0.0         2469   \n",
      "\n",
      "                     post_hour  post_day  \n",
      "time                                      \n",
      "2011-06-22 20:29:14         20         2  \n",
      "2012-06-26 20:02:09         20         1  \n",
      "2013-05-19 00:56:11          0         6  \n",
      "2014-03-04 16:26:05         16         1  \n",
      "2014-07-03 04:37:27          4         3  \n"
     ]
    }
   ],
   "source": [
    "##################### CLEANING DATA #####################\n",
    "\n",
    "#deleted, ranking are all null. drop those columns.\n",
    "df.drop(['deleted', 'ranking'], axis=1,inplace = True)\n",
    "\n",
    "#parent's ids are irrelevant to predict scores\n",
    "df.drop(['parent'], axis = 1, inplace = True)\n",
    "\n",
    "#time is in unix, change it to mm/dd/yy hh:mm:ss \n",
    "df=df.set_index(pd.to_datetime(df['time'], unit='s'))\n",
    "\n",
    "#dead is boolean. those null = False. transform it to 1 and 0\n",
    "df['dead'].fillna(value=False, inplace  = True)\n",
    "df[['dead']]=df[['dead']].astype(int)\n",
    "\n",
    "#assume descendants null = 0\n",
    "df['descendants'].fillna(value =0, inplace =True)\n",
    "\n",
    "#get_dummies for type: job, poll, story\n",
    "#type_dum =pd.get_dummies(df['type'], drop_first =True)\n",
    "#df=pd.concat([df,type_dum], axis=1)\n",
    "#df = df.sort_index()\n",
    "\n",
    "#map each type to numeric\n",
    "df['type_numeric']= df['type'].map({'job' :0,'story':1, 'poll':2})\n",
    "\n",
    "#add len of text to part of df\n",
    "df['text_length'] = df['text'].str.len()\n",
    "#creating column for hour when story is posted\n",
    "df['post_hour'] = pd.DatetimeIndex(df.index).hour\n",
    "df['post_hour'].fillna(value = df['post_hour'].mean(), inplace = True)\n",
    "df['post_day'] = pd.DatetimeIndex(df.index).dayofweek #0 for monday\n",
    "df['post_day'].fillna(value = df['post_day'].mean(), inplace = True)\n",
    "\n",
    "#drop unix time\n",
    "df.drop(['time'],axis = 1, inplace = True)\n",
    "\n",
    "print df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top 5 Authors base on mean score: by\n",
      "themanthatfell    1344.0\n",
      "detectify         1156.0\n",
      "thy_inquisitor     662.0\n",
      "huhtenberg         659.0\n",
      "needmoney          620.0\n",
      "Name: score, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################### VISUALISATION #####################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#which Q period has the most hackernews\n",
    "bar_chart=df['id'].groupby(pd.TimeGrouper(\"Q\")).count().plot(kind='bar', title='No. of Hackernews per month')\n",
    "bar_chart.x_label = 'Date'\n",
    "bar_chart.y_label = 'Quantity'\n",
    "fig = bar_chart.get_figure()\n",
    "fig.savefig('y.png')\n",
    "\n",
    "\n",
    "#groupby scores and count stories. check what is the most common score for a story\n",
    "score_chart = df['id'].groupby(df['score']).count().plot(kind ='bar',title='Score for story')\n",
    "score_chart.set_xlabel('Score')\n",
    "score_chart.set_ylabel('Number of stories')\n",
    "fig2 = score_chart.get_figure()\n",
    "fig2.savefig('Score_stories.png')\n",
    "\n",
    "#which hour and day have the most post \n",
    "hour_chart = df['score'].groupby(df['post_hour']).mean().plot(kind ='line', title ='Average Score by hour')\n",
    "hour_chart.set_xlabel('Hours')\n",
    "hour_chart.set_ylabel('Score')\n",
    "fig3 = hour_chart.get_figure()\n",
    "fig3.savefig('hour_chart.png')\n",
    "\n",
    "#which authors consistently get on the front page\n",
    "average_score = df['score'].groupby(df['by']).mean()\n",
    "print \"\\n\"\n",
    "print 'Top 5 Authors base on mean score:' , average_score.sort_values(ascending = False).head(5) #top 5 author with highest score\n",
    "print \"\\n\"\n",
    "\n",
    "'''\n",
    "#!!! Nan for score and type...\n",
    "#scatter plot score vs type\n",
    "score_type = df.plot(kind = 'scatter', x = df['type_numeric'], y = df['score'], alpha = 0.2)\n",
    "score_type.set_xlabel('type')\n",
    "score_type.set_ylabel('score')\n",
    "fig3 = score_type.get_figure()\n",
    "fig3.savefig('Score_type.png')\n",
    "'''\n",
    "\n",
    "\n",
    "##################### TEXT ANALYSIS USING NAIVE BAYES #####################\n",
    "\n",
    "#ngram text analysis on 68 text. \n",
    "#print df.head()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "CV = CountVectorizer(ngram_range=(1,99999))\n",
    "df_text = df[['score', 'text']].copy()\n",
    "df_text.dropna(axis=0, inplace = True)\n",
    "X = CV.fit_transform(df_text['text'])\n",
    "Y = df_text['score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, random_state =3)\n",
    "\n",
    "def accuracy_report(_clf):\n",
    "    training_accuracy = _clf.score(xtrain, ytrain)\n",
    "    test_accuracy = _clf.score(xtest, ytest)\n",
    "    print \"Accuracy on test data: %0.2f%%\" % (100 * test_accuracy)\n",
    "    print \"Accuracy on training data: %0.2f%%\" % (100 * training_accuracy)\n",
    "\n",
    "print '===Naive Bayes: Feature = text; Target = score.===\\n'\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print \"MultinomialNB:\"\n",
    "clf_m = MultinomialNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_m)\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "print \"BernoulliNB:\"\n",
    "clf_b = BernoulliNB().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_b)\n",
    "\n",
    "print \"\\n\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print \"Logistic Regression:\"\n",
    "clf_lr = LogisticRegression().fit(xtrain, ytrain)\n",
    "accuracy_report(clf_lr)\n",
    "\n",
    "\n",
    "#find the most common words among highest score.\n",
    "\n",
    "print \"============\"\n",
    "print df[df['text'].notnull()].shape\n",
    "\n",
    "##################### KNN/Kfold ##################### \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print df.info()\n",
    "\n",
    "X = df[['deleted', 'dead', 'descendants','poll','story', 'post_hour','post_day']]\n",
    "y = np.asarray(df.score, dtype ='|S6')\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X,y)\n",
    "print knn.predict([[1,0,0,0,1,10,4]])\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
